mport pandas as pd
import numpy as np
import re
import math
from urllib.parse import urlparse
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

class Detector:
    def __init__(self):
        # using random forest cause it works well for this stuff
        self.clf = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42)
        self.cols = []

    def entropy_calc(self, s):
        # figure out how random the text looks (higher = messy)
        if not s:
            return 0
        e = 0
        for x in set(s):
            p = float(s.count(x)) / len(s)
            e += - p * math.log(p, 2)
        return e

    def get_feats(self, u):
        # grab the useful info from the link
        try:
            p = urlparse(u)
            d = p.netloc.replace('www.', '') # clean up domain
            pt = p.path
            
            # add everything into a dict 'f'
            f = {
                'len_u': len(u),
                'len_d': len(d),
                'len_p': len(pt),
                'dots': u.count('.'),
                'hyph': u.count('-'),
                'under': u.count('_'),
                'slash': u.count('/'),
                'q_mark': u.count('?'),
                'eq': u.count('='),
                'at': u.count('@'),
                'perc': u.count('%'),
                'dig': sum(c.isdigit() for c in u),
                'let': sum(c.isalpha() for c in u),
                'is_ip': 1 if re.match(r'^\d+\.\d+\.\d+\.\d+$', d) else 0,
                'ent': self.entropy_calc(u), # check randomness
                'https': 1 if p.scheme == 'https' else 0
            }
            
            # check for sketchy words
            kws = [
                'login', 'signin', 'secure', 'account', 'verify', 
                'banking', 'update', 'confirm', 'password', 'service', 
                'webscr', 'paypal', 'ebay', 'amazon', 'apple'
            ]
            
            for k in kws:
                f[f'k_{k}'] = 1 if k in u.lower() else 0
                
            return f

        except Exception as e:
            print(f"oops, failed on {u}: {e}")
            return None

    def fit_model(self, x_in, y_in):
        # teach the model using the list
        print(f"crunching numbers for {len(x_in)} links...")
        
        data = []
        clean_y = []
        
        for i, u in enumerate(x_in):
            v = self.get_feats(u)
            if v:
                data.append(v)
                clean_y.append(y_in[i])
        
        df = pd.DataFrame(data)
        self.cols = df.columns.tolist()
        
        print(f"training on {len(df)} rows...")
        
        # split it up so we can test it later
        x_tr, x_te, y_tr, y_te = train_test_split(
            df, clean_y, test_size=0.2, random_state=42
        )
        
        self.clf.fit(x_tr, y_tr)
        
        # see how we did
        preds = self.clf.predict(x_te)
        acc = accuracy_score(y_te, preds)
        print(f"done! accuracy is around: {acc:.2%}")
        print("-" * 60)

    def check_url(self, u):
        # run a quick check on a new link
        v = self.get_feats(u)
        
        # FIX: Return a tuple of 3 values to prevent crash in main loop
        if not v:
            return "Error", 0.0, {}
            
        df = pd.DataFrame([v])
        
        # make sure columns match what we trained on
        for c in self.cols:
            if c not in df.columns:
                df[c] = 0
        df = df[self.cols]
        
        # get probability
        p = self.clf.predict_proba(df)[0][1]
        res = "PHISHING" if p > 0.5 else "LEGITIMATE"
        
        return res, p, v

# --- Main Run ---
if __name__ == "__main__":
    
    # fake dataset setup
    u_list = [
        "https://www.google.com", "https://www.youtube.com", "https://github.com/login",
        "https://stackoverflow.com", "https://www.amazon.com", "https://www.wikipedia.org",
        "https://www.reddit.com", "https://www.microsoft.com", "https://www.apple.com",
        "https://pypi.org/project/pandas/", "https://docs.python.org/3/library",
        "http://secure-paypal-login.com.cgi-bin.xyz", "http://update-amazon-payment.net",
        "http://192.168.0.1/verify", "http://apple-id-security-check.info",
        "https://netflix-account-restart.com", "http://login-facebook-secure.badsite.com",
        "http://wells-fargo-banking.confirm-identity.com", "http://x82js92.com/login",
        "https://verify-instagram-badge.xyz", "http://google-drive-secure-share.net"
    ]
    y_list = [0]*11 + [1]*10 

    # fire it up
    bot = Detector()
    bot.fit_model(u_list, y_list)

    print("\n" + "="*60)
    print("    URL CHECKER (CMD MODE)")
    print("="*60)
    print("enter a link to check, or 'exit' to quit")
    
    while True:
        txt = input("\nLink: ").strip()
        
        if txt.lower() in ['exit', 'quit']:
            break
            
        if not txt:
            continue
            
        res, conf, f_debug = bot.check_url(txt)
        
        # pretty colors for terminal
        c_code = "\033[91m" if res == "PHISHING" else "\033[92m"
        rst = "\033[0m"
        
        print(f"\nVerdict: {c_code} {res} {rst}")
        print(f"Certainty: {conf:.2%}")
        
        if res == "PHISHING":
            print(" Why it looks bad:")
            if f_debug.get('is_ip'): print("   - Looks like an IP address")
            if f_debug.get('ent', 0) > 4.5: print("   - Text looks super random")
            if f_debug.get('hyph', 0) > 2: print("   - Too many hyphens")
            for k, val in f_debug.items():
                if 'k_' in k and val == 1:
                    print(f"   - Found sketchy word: '{k.split('_')[-1]}'")
